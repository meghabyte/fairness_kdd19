Across the United States, data-driven decision making algorithms are increasingly employed to predict the likelihood of future crimes by defendants. These algorithmic predictions are utilized by judges to make sentencing decisions for defendants (e.g. setting the bond amount; time to be spent in jail). <br> <br> Data-driven decision making algorithms use historical data about past defendants to learn about factors that highly correlate with criminality. For instance, the algorithm may learn from past data that: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.  A defendant with a lengthy criminal history is more likely to reoffend if set free—compared to a first time defender, or <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Defendants belonging to certain groups (e.g. residents of neighborhoods with high crime rate) are more likely to reoffend if set free. <br> However, algorithms are not perfect and they inevitably make errors—although the error rate is usually very low, <strong><i>the algorithm’s decision can have a significant impact on some defendants’ lives.</i></strong> A defendant falsely predicted to reoffend can unjustly face longer sentences, while a defendant false predicted to not reoffend may commit a crime that was preventable.<br> <br> Our goal is to assess how fair you believe different predictive algorithms are based on their errors. You will be offered a series of <b>20 questions</b> and you will be asked to <i><strong>choose which algorithm makes predictions that you find to be more discriminatory</strong></i>. Each question shows 10 (hypothetical) defendants and their demographic information. Here is an example. <br><br><img src='/static/figures/interface.png' alt='Explanation Field' width='65%'> <br><br>Demographic information is represented by colors: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. White profile = Caucasian race <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Black profile = African American race <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. Blue Background = Male Gender <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4. Pink Background = Female Gender <br> You will see the predictions made for these 10 defendants by Algorithm 1 and 2. Both algorithms either predict that the defendant will reoffend <b>(red)</b>, or predict that he/she will not reoffend <b>(green)</b>. You will also be shown the <b>true outcome</b> - whether each defendant actually committed another crime. <i>Based on this information, you will be asked to select that algorithm that you believe is the most discriminatory, and fill out the explanation field specifying the reasoning behind your choice.</i><br><br>
<img src='/static/figures/select1.png' alt='Explanation Field' width='40%'>  <br><br> In the first dropdown, choose the demographic information that you think the algorithm is most discriminatory with respect to.  For instance, you might consider Algorithm 1 more discriminatory across racial groups. <br><br> <img src='/static/figures/select2.png' alt='Explanation Field' width='40%'> <br><br>  In the second dropdown, choose the metric along which you think the algorithm is most discriminatory. For instance, you may think Algorithm 1 is more discriminatory because it makes 1 correct prediction for African-American and 5 correct predictions for Caucasians.  <br><br> <img src='/static/figures/select3.png' alt='Explanation Field' width='40%'> <br><br> <ul style='list-style-type:disc'><li>If you think there are multiple reasons, pick the one you find most significant.</li><li>The 10 defendants are chosen such that the predictions the algorithm makes for them is representative of how the it performs overall and on the entire population of defendants.</li><li>Every question corresponds to a different set of individuals and algorithms. <i>Information provided in previous questions should not affect your choice for the current question.</i></li></ul><br>The average response time for a single question is around 1 minute. If you do not complete a single question within 30 minutes, the task will time out and will be marked as incomplete. <b>You will be compensated for your time only if you complete the task. </b> The complete information sheet for this study (goals, procedures, risks, etc.) can be found <a href='/static/information/infosheet.pdf' target='_blank'>here</a>. By pressing the proceed button, you have agreed that you have read and understood <a href='/static/information/consentform.pdf' target='_blank'>this consent form</a>.