Data-driven algorithms are increasingly employed to diagnose various medical conditions, such as risk for heart disease or various forms of cancer. They can find patterns and links in medical records that previously required great levels of expertise or time from human doctors. Algorithmic diagnoses are utilized by health-care professionals to create personalized treatment plans for patients (e.g. whether the patient should undergo surgery, chemotherapy, etc.). <br> <br> Data-driven decision making algorithms use historical data about past patients to learn about factors that highly correlate with risk for cancer. These algorithms use historical medical data of past patients to learn about factors that highly correlate with the medical condition in question (e.g. skin cancer). For instance, the algorithm may learn from past data that: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.  A patient with a family history of skin cancer has a higher risk of developing skin cancer; or <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Patients belonging to certain groups (e.g. people with a certain skin tone, or people of a certain gender) are more likely to develop skin cancer. <br><br> However, algorithms are not perfect and they inevitably make errors—although the error rate is usually very low, <strong><i>the algorithm’s decision can have a significant impact on patients' lives.</i></strong> <br>A patient falsely diagnosed with cancer may <b>unnecessarily go through high-risk and costly medical treatments</b>, while a patient falsely labeled as cancer-free may face <b>a lower chance of survival</b>.<br> <br> Our goal is to assess how discriminatory you believe different algorithms are based on their errors in predicting risk for skin cancer. You will be offered a series of <b>20 questions</b> and you will be asked to <i><strong>choose which algorithm makes predictions that you find to be more discriminatory</strong></i>.  Each question shows 10 (hypothetical) patients and their demographic information. Here is an example. <br><br><img src='/static/figures/interface_med.png' alt='Explanation Field' width='50%'> <br><br>Demographic information is represented by colors: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. White profile = Caucasian race (acronym W) <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Black profile = African American race (acronym B) <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. Blue Background = Male Gender (acronym M) <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4. Pink Background = Female Gender (acronym F) <br> You will see the predictions made for these 10 patients by Algorithm 1 and 2. Both algorithms either predict the patient has high-risk for cancer <b>(red)</b>, or label him/her with low risk for cancer <b>(green)</b>. You will also be shown the <b>true outcome</b> -  whether each patient actually suffers from skin cancer. <i>Based on this information, you will be asked to select that algorithm that you believe is the least discriminatory, and fill out the explanation field specifying the reasoning behind your choice. </i><br><br>